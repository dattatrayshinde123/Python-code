{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dattatrayshinde123/Python-code/blob/main/Copy_of_ConvolutionNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6eJ32zNjYlo"
      },
      "source": [
        "# **Convolutional Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P8VaYSMpiMpl"
      },
      "outputs": [],
      "source": [
        "#Import required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiI4Ja1njXR-"
      },
      "source": [
        "# **Part 1 : Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHRv_IiBafPx"
      },
      "source": [
        "## Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ID3nRu8T7os",
        "outputId": "9cc00ea4-49ca-431f-9f35-6cd8143af227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8005 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Define ImageDataGenerator for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Generate batches of augmented data from training set\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset/training_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrkSc2uRfSNt"
      },
      "source": [
        "## Test DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1NLLc5jfW-t",
        "outputId": "6e4621c7-9317-4d19-9613-bc7c712d234d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2005 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generate batches of augmented data from test set\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset/test_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NksvsZ0HbKMu"
      },
      "source": [
        "# **Part 2: Define CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cjS_SGawaRAE"
      },
      "outputs": [],
      "source": [
        "#Initialize The code\n",
        "cnn =tf.keras.models.Sequential()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7y-zynDsrg6"
      },
      "source": [
        "##First Convolutional Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8K-2Yd28hYQs"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR4UYbxxCxqA"
      },
      "source": [
        "#2.Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gkAW0SmuC4UO"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXmZjvsvBPaZ"
      },
      "source": [
        "# 3.Second Convolutional Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9JEuh6Uyha-2"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6dySF5mDP9y"
      },
      "source": [
        "#4.Flattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aVIQSSfGhb38"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lT4tBwuD7iE"
      },
      "source": [
        "#5.Full connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HCYV0ySQhdBS"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN93xg7HE7Gl"
      },
      "source": [
        "# 6.Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y2-bHCCChezx"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8ff4drkE_CI"
      },
      "source": [
        "# **Part 3. Training The CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubodHXBSGKiH"
      },
      "source": [
        "Compile the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_-YDPzLaapWJ"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['Accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65rES6C0FFWG"
      },
      "source": [
        "**Train The Model on train data and Evaluating on test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFKM3Bq6FCm7",
        "outputId": "0ceeeb9f-1a21-4858-a692-d0ea9807c58d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "251/251 [==============================] - 2017s 8s/step - loss: 0.6624 - Accuracy: 0.5998 - val_loss: 0.6523 - val_Accuracy: 0.6020\n",
            "Epoch 2/25\n",
            "251/251 [==============================] - 114s 453ms/step - loss: 0.5932 - Accuracy: 0.6838 - val_loss: 0.6001 - val_Accuracy: 0.6833\n",
            "Epoch 3/25\n",
            "251/251 [==============================] - 111s 443ms/step - loss: 0.5528 - Accuracy: 0.7169 - val_loss: 0.5524 - val_Accuracy: 0.7302\n",
            "Epoch 4/25\n",
            "251/251 [==============================] - 103s 411ms/step - loss: 0.5230 - Accuracy: 0.7388 - val_loss: 0.5266 - val_Accuracy: 0.7446\n",
            "Epoch 5/25\n",
            "251/251 [==============================] - 107s 428ms/step - loss: 0.4944 - Accuracy: 0.7580 - val_loss: 0.4994 - val_Accuracy: 0.7621\n",
            "Epoch 6/25\n",
            "251/251 [==============================] - 109s 435ms/step - loss: 0.4785 - Accuracy: 0.7660 - val_loss: 0.4697 - val_Accuracy: 0.7845\n",
            "Epoch 7/25\n",
            "251/251 [==============================] - 111s 441ms/step - loss: 0.4602 - Accuracy: 0.7808 - val_loss: 0.4678 - val_Accuracy: 0.7840\n",
            "Epoch 8/25\n",
            "251/251 [==============================] - 110s 438ms/step - loss: 0.4409 - Accuracy: 0.7935 - val_loss: 0.4710 - val_Accuracy: 0.7845\n",
            "Epoch 9/25\n",
            "251/251 [==============================] - 112s 447ms/step - loss: 0.4305 - Accuracy: 0.7985 - val_loss: 0.4441 - val_Accuracy: 0.7865\n",
            "Epoch 10/25\n",
            "251/251 [==============================] - 110s 436ms/step - loss: 0.4165 - Accuracy: 0.8031 - val_loss: 0.4480 - val_Accuracy: 0.7930\n",
            "Epoch 11/25\n",
            "251/251 [==============================] - 118s 468ms/step - loss: 0.4054 - Accuracy: 0.8129 - val_loss: 0.4576 - val_Accuracy: 0.7965\n",
            "Epoch 12/25\n",
            "251/251 [==============================] - 113s 452ms/step - loss: 0.3961 - Accuracy: 0.8137 - val_loss: 0.4807 - val_Accuracy: 0.7835\n",
            "Epoch 13/25\n",
            "251/251 [==============================] - 107s 427ms/step - loss: 0.3826 - Accuracy: 0.8259 - val_loss: 0.4789 - val_Accuracy: 0.7800\n",
            "Epoch 14/25\n",
            "251/251 [==============================] - 112s 448ms/step - loss: 0.3717 - Accuracy: 0.8317 - val_loss: 0.4828 - val_Accuracy: 0.7935\n",
            "Epoch 15/25\n",
            "251/251 [==============================] - 107s 424ms/step - loss: 0.3568 - Accuracy: 0.8391 - val_loss: 0.4625 - val_Accuracy: 0.8030\n",
            "Epoch 16/25\n",
            "251/251 [==============================] - 108s 431ms/step - loss: 0.3567 - Accuracy: 0.8336 - val_loss: 0.5024 - val_Accuracy: 0.7825\n",
            "Epoch 17/25\n",
            "251/251 [==============================] - 107s 425ms/step - loss: 0.3248 - Accuracy: 0.8550 - val_loss: 0.4493 - val_Accuracy: 0.8120\n",
            "Epoch 18/25\n",
            "251/251 [==============================] - 111s 443ms/step - loss: 0.3203 - Accuracy: 0.8608 - val_loss: 0.4372 - val_Accuracy: 0.8195\n",
            "Epoch 19/25\n",
            "251/251 [==============================] - 106s 424ms/step - loss: 0.3069 - Accuracy: 0.8665 - val_loss: 0.4509 - val_Accuracy: 0.8170\n",
            "Epoch 20/25\n",
            "251/251 [==============================] - 115s 460ms/step - loss: 0.2904 - Accuracy: 0.8751 - val_loss: 0.4612 - val_Accuracy: 0.8214\n",
            "Epoch 21/25\n",
            "251/251 [==============================] - 108s 431ms/step - loss: 0.2847 - Accuracy: 0.8753 - val_loss: 0.5148 - val_Accuracy: 0.8095\n",
            "Epoch 22/25\n",
            "251/251 [==============================] - 112s 447ms/step - loss: 0.2678 - Accuracy: 0.8858 - val_loss: 0.4653 - val_Accuracy: 0.8180\n",
            "Epoch 23/25\n",
            "251/251 [==============================] - 108s 431ms/step - loss: 0.2484 - Accuracy: 0.8928 - val_loss: 0.5190 - val_Accuracy: 0.8195\n",
            "Epoch 24/25\n",
            "251/251 [==============================] - 112s 445ms/step - loss: 0.2466 - Accuracy: 0.8999 - val_loss: 0.4987 - val_Accuracy: 0.8145\n",
            "Epoch 25/25\n",
            "251/251 [==============================] - 116s 462ms/step - loss: 0.2312 - Accuracy: 0.9032 - val_loss: 0.4721 - val_Accuracy: 0.8284\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d54b951e680>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "cnn.fit(x=training_set,validation_data=test_set,epochs=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUYq7FWvJqPz"
      },
      "source": [
        "# **Part 4.Making Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "IH493bXuZh08",
        "outputId": "2e260362-3b22-4912-a1d7-9544d78edf6f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cnn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c93c63fbba13>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "test_image=image.load_img('/content/drive/MyDrive/dataset/single_prediction/cat_or_dog_1.jpg',target_size=(64,64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "result=cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "\n",
        "if result[0][0]==1:\n",
        "  prediction='dog'\n",
        "else:\n",
        "  prediction='cat'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OtIIBd9gxnyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc28d2e5-376a-4e9b-9729-19150b417f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n"
          ]
        }
      ],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UHq6ijauE7Iw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_ngBkuBW3ktc-ETicJ64mH3WnftbvOzF",
      "authorship_tag": "ABX9TyOp36MZ7TTkgSjhWa2K6te9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}